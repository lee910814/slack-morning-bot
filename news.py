import feedparser
import re
from datetime import datetime
from collections import defaultdict

def get_news_summary():
    """AI ì—†ì´ ë˜‘ë˜‘í•œ ë‰´ìŠ¤ ìš”ì•½"""
    
    try:
        # ì—¬ëŸ¬ RSS ì†ŒìŠ¤ (ë” í’ë¶€í•œ ì •ë³´)
        feeds = [
            {
                'url': 'https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko',
                'name': 'Google News'
            },
            {
                'url': 'https://www.hani.co.kr/rss/',
                'name': 'í•œê²¨ë ˆ'
            },
            {
                'url': 'http://www.hani.co.kr/rss/newsmaker/',
                'name': 'í•œê²¨ë ˆ ë‰´ìŠ¤ë©”ì´ì»¤'
            }
        ]
        
        all_news = []
        
        # ëª¨ë“  í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
        for feed_info in feeds:
            try:
                feed = feedparser.parse(feed_info['url'])
                for entry in feed.entries[:10]:  # ê° ì†ŒìŠ¤ì—ì„œ 10ê°œì”©
                    all_news.append({
                        'title': clean_title(entry.title),
                        'link': entry.get('link', ''),
                        'source': feed_info['name'],
                        'summary': entry.get('summary', '')[:100]  # ìš”ì•½ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                    })
            except:
                continue
        
        # ì¤‘ìš”ë„ ê¸°ë°˜ ì •ë ¬ ë° ì„ íƒ
        important_news = filter_and_rank_news(all_news)
        
        # í¬ë§·íŒ…
        result = format_news(important_news[:5])
        
        return result
        
    except Exception as e:
        return f"ğŸ“° ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"


def clean_title(title):
    """ì œëª© ì •ë¦¬ (ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°)"""
    # ì¶œì²˜ í‘œì‹œ ì œê±° (ì˜ˆ: "- ì—°í•©ë‰´ìŠ¤")
    title = re.sub(r'\s*-\s*[\w\s]+$', '', title)
    # ì´ìƒí•œ ê¸°í˜¸ ì œê±°
    title = re.sub(r'[ã€ã€‘\[\]]', '', title)
    return title.strip()


def filter_and_rank_news(news_list):
    """ì¤‘ìš” ë‰´ìŠ¤ í•„í„°ë§ ë° ìˆœìœ„ ë§¤ê¸°ê¸°"""
    
    # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ (ì¤‘ìš”ë„ ì ìˆ˜)
    keywords = {
        'ì •ì¹˜': {
            'keywords': ['ëŒ€í†µë ¹', 'ì •ë¶€', 'êµ­íšŒ', 'ì¥ê´€', 'ì—¬ë‹¹', 'ì•¼ë‹¹', 'ì„ ê±°'],
            'weight': 3
        },
        'ê²½ì œ': {
            'keywords': ['ì£¼ì‹', 'ì½”ìŠ¤í”¼', 'í™˜ìœ¨', 'GDP', 'ê¸ˆë¦¬', 'ë¶€ë™ì‚°', 'ì‚¼ì„±', 'SK', 'í˜„ëŒ€'],
            'weight': 3
        },
        'ì‚¬íšŒ': {
            'keywords': ['ì‚¬ê³ ', 'í™”ì¬', 'ë²”ì£„', 'ì¬ë‚œ', 'ë‚ ì”¨', 'í­ì„¤', 'í­ìš°'],
            'weight': 2
        },
        'êµ­ì œ': {
            'keywords': ['ë¯¸êµ­', 'ì¤‘êµ­', 'ì¼ë³¸', 'ë¶í•œ', 'ì „ìŸ', 'íŠ¸ëŸ¼í”„', 'UN'],
            'weight': 2
        },
        'ê¸°ìˆ ': {
            'keywords': ['AI', 'ì¸ê³µì§€ëŠ¥', 'ì±—GPT', 'í…ŒìŠ¬ë¼', 'ì• í”Œ', 'êµ¬ê¸€'],
            'weight': 1
        }
    }
    
    # ì¤‘ë³µ ì œê±° (ìœ ì‚¬í•œ ì œëª©)
    unique_news = remove_duplicates(news_list)
    
    # ì ìˆ˜ ê³„ì‚°
    scored_news = []
    for news in unique_news:
        score = 0
        category = 'ê¸°íƒ€'
        
        for cat, info in keywords.items():
            for keyword in info['keywords']:
                if keyword in news['title']:
                    score += info['weight']
                    category = cat
                    break
        
        news['score'] = score
        news['category'] = category
        scored_news.append(news)
    
    # ì ìˆ˜ìˆœ ì •ë ¬
    scored_news.sort(key=lambda x: x['score'], reverse=True)
    
    return scored_news


def remove_duplicates(news_list):
    """ìœ ì‚¬í•œ ë‰´ìŠ¤ ì œê±°"""
    unique = []
    seen_keywords = set()
    
    for news in news_list:
        # ì£¼ìš” ë‹¨ì–´ ì¶”ì¶œ (3ê¸€ì ì´ìƒ)
        words = [w for w in re.findall(r'\w+', news['title']) if len(w) >= 3]
        
        # ê²¹ì¹˜ëŠ” ë‹¨ì–´ê°€ 2ê°œ ì´ìƒì´ë©´ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼
        current_set = set(words[:5])  # ì• 5ê°œ ë‹¨ì–´ë§Œ ë¹„êµ
        
        is_duplicate = False
        for seen in seen_keywords:
            if len(current_set & seen) >= 2:
                is_duplicate = True
                break
        
        if not is_duplicate:
            unique.append(news)
            seen_keywords.add(frozenset(current_set))
    
    return unique


def format_news(news_list):
    """ë‰´ìŠ¤ í¬ë§·íŒ…"""
    
    result = "ğŸ“° **ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤**\n"
    result += f"_{datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ ê¸°ì¤€')}_\n\n"
    
    for i, news in enumerate(news_list, 1):
        # ì´ëª¨ì§€ ë§¤í•‘
        emoji_map = {
            'ì •ì¹˜': 'ğŸ›ï¸',
            'ê²½ì œ': 'ğŸ’°',
            'ì‚¬íšŒ': 'ğŸ™ï¸',
            'êµ­ì œ': 'ğŸŒ',
            'ê¸°ìˆ ': 'ğŸ’»',
            'ê¸°íƒ€': 'ğŸ“Œ'
        }
        
        emoji = emoji_map.get(news['category'], 'ğŸ“Œ')
        
        result += f"{emoji} **{news['category']}**\n"
        result += f"{i}. {news['title']}\n"
        
        # ìš”ì•½ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if news.get('summary') and len(news['summary']) > 20:
            result += f"   ğŸ’¬ {news['summary']}\n"
        
        result += f"   ğŸ”— [ê¸°ì‚¬ ë³´ê¸°]({news['link']})\n\n"
    
    return result


# ë°±ì—…: ì´ˆê°„ë‹¨ ë²„ì „
def get_simple_news():
    """ê°€ì¥ ê°„ë‹¨í•œ ë²„ì „ (ë°±ì—…ìš©)"""
    try:
        feed = feedparser.parse("https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko")
        
        result = "ğŸ“° **ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤**\n\n"
        
        for i, entry in enumerate(feed.entries[:5], 1):
            result += f"{i}. {entry.title}\n"
            result += f"   ğŸ”— {entry.link}\n\n"
        
        return result
    except:
        return "ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."